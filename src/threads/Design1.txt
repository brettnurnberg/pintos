CIS 520 - Programming Project #1

                   
---- GROUP ----

Zach Doll <zacharydoll@k-state.edu>
Brandt Hill <djbrandt@k-state.edu>
Brett Nurnberg <brettnurnberg@k-state.edu>


---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for
>> the TA, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation,
>> course text, lecture notes, and course staff.


                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In timer.c:
  static struct list sleep_list; /* List to hold sleeping threads. */
  static struct lock sleep_lock; /* Lock to insert threads onto sleep_list. */

In thread.h:
  /* The sleep structure holds all necessary data for a sleeping thread. */
  struct sleep
  {
    struct semaphore sema;    /* Sema to block thread. */
    struct list_elem elem;    /* Used for list of sleepers. */
    int64_t wake_time;        /* Time to wake thread. */
  };

  /* Thread now contains sleep struct to hold sleep data. */
  struct thread
  {
  ...
    struct sleep sleep;    /* Sleeping thread data */
  ...
  }
  

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to your timer_sleep(),
>> including the effects of the timer interrupt handler.

We calculate the wake time (in ticks) of the thread and set the thread's
sleep struct wake time to this time. We initialize the sleep struct's
semaphore with a value of 0 to block the thread. We then acquire a lock
before inserting the thread onto the list of sleeping threads. The thread
is inserted on the sleep list, ordered by increasing wake time. The lock 
is then released and the thread is blocked using the semaphore.

In the interrupt handler, we check if there are any sleeping threads. If so,
we look at the top sleeping thread and see if it needs to be woken up. If so,
we wake the thread and remove it from the list. We continue to check the 
next sleeping thread until they don't need to be woken up. (The wake time 
is greater than the current time)



>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

1. We ordered the list of sleeping threads by wake time so that we
   do not have to check the entire list of sleeping threads every interrupt.
   Therefore, we check the least number of threads possible.
   
2. We do not attempt to wake/check threads if the list of sleeping threads
   is empty.
   
3. We calculate the thread wake time in timer_sleep as opposed to saving
   the amount of ticks to sleep. We therefore do not have to calculate the
   wake time every interrupt.




---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We added a sleep_lock that must be acquired before adding a thread
to the list of sleeping threads. This is necessary because the 
list of sleeping threads is a global variable.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

In order to avoid this race condition, we supplied each thread
with its own semaphore, initialized to 0. This way, each thread
can only be blocked or unblocked on its own semaphore.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> other designs that you considered?

We first attempted to implement timer_sleep using a single semaphore,
but the semaphore value was not atomic because it was shared between all
threads. Therefore, the value could be changed in a race condition when
timer_interrupt was called.

Our design is superior to our previous designs because each thread has
its own semaphore to block and unblock on, thereby preventing race
conditions. Our final design also implements an ordered list (by wake
time), which significantly reduces time spent in the interrupt handler.



             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.h
  /* Priority element used to track donated priorities. */
  struct priority_elem
    {
      int priority;            /* Donated priority. */
      struct lock *lock;       /* Lock for which priority was donated. */
      struct list_elem elem;   /* List element. */
    };

    /* Added members for tracking priority donation. */
    struct thread
    {
    ...
      struct list priorities;  /* List of donated priorities. */
      struct lock *lock_req;   /* Lock that thread is waiting on. */
    ...
    }
    
    
>> B2: Explain the data structure used to track priority donation.

Each thread contains an ordered list of priority elements. Each priority
element corresponds to a single lock that has donated a priority to that
thread. The priority element contains the donated priority, the lock from
which the priority was donated, and a list element to be inserted on a list.

When a priority is donated, a new priority element is created and inserted
on the list, ordered by decreasing priority. The end of the priority list
contains a priority element corresponding to the thread's original priority.



---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

When downing a semaphore, the blocked thread is now inserted into
the list of waiters in order of decreasing priority. This way,
whenever a waiter is popped from the front of the waiter list, it
will always have the highest priority.


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

We first check that the thread is not already waiting on a lock.
We then set the thread's required lock to the lock it is acquiring.
If the lock is already held by another thread, and the current thread's
priority is higher than lock holder's priority, we donate the current
threads priority to the lock holder. This is done by inserting a priority
element into the lock holder's priority list. If a waiter on this lock has
previously donated to this lock holder, we also remove the corresponding
priority element so that only one waiter per lock can donate.

In order to handle nested donation, we then check if the lock holder is
also waiting on a lock. If so, we loop and donate to the lock holder's
lock holder. We loop until the a thread is no longer waiting on a lock.


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

When a thread that has received a donated priority releases a lock,
we remove the priority element that corresponds to that donation.
We then set the priority of the thread that is releasing the lock
to the highest donated priority in its priority list.


---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

If two threads of the same priority are both ready, one could potentially
lower its priority while the other was in the middle of lowering its own
priority. Say, one priority 31 thread is running and another is ready.
The first thread may lower its priority (say to 27), but before it sets
its priority, the other thread interrupts due to a time slice expiring and also
lowers its priority (say to 29). The second thread would then (incorrectly)
yield to the first thread, as its priority would still be 31.

Our implementation avoids this thread from continuing by then yielding the
thread after the priority has been lowered to 27. The priority 29 thread
would then correctly resume running.

We cannot use a lock to prevent this race because there is no global variable
involved. Each thread has its own priority and list of donated priorities. We
could, however, disable interrupts until the priority has been set. This is
not entirely necessary, however, as the thread will immediately yield to
higher priority threads once it resumes.


---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We originally tried to implement priority donation by storing a single donated
integer which would hold the highest donated priority. This did not work for
multiple donation because once one lock was released by the thread, its
priority was reverted to its original priority, when it should have been
set to the highest remaining waiting thread's priority.

Our implementation of a list of donated priorities is superior because it contains
the original priority and exactly one priority element for each lock for which 
the priority has been donated. This allows for multiple donation. Our implementation
also orders the list of priority elements by decreasing priority, which allows the
original priority (lowest priority) and the current priority (highest priority) to
be accessed without searching through the list, thereby increasing efficiency.


              ADVANCED SCHEDULER [EXTRA CREDIT]
              =================================

NOT IMPLEMENTED.